# Rashmi-Sundareswara (https://github.com/user-attachments/files/25399923/README.md)


**Research Scientist | Machine Learning & AI Safety**

I'm a Research Scientist with 17+ years of experience designing, developing, and prototyping ML systems for government (DARPA / IARPA) applications in vehicle (GM) aerospace (Boeing) manufacturing, fault prediction, and quantum applications.

## About My GitHub

You'll notice this profile doesn't contain extensive code repositories from my professional work. This is by design, not by accident. My previous research at HRL Laboratories and on government-funded projects involved proprietary systems with strict intellectual property policies that prohibited public code sharing.

### Public Contributions

While most of my work remains proprietary, I have contributed to public repositories where permitted:

**DARPA Quantum Benchmarking (QB-GSEE)**: Contributed to machine learning components for quantum benchmarking as part of DARPA's Quantum Benchmarking initiative.
- Repository: [qb-gsee-benchmark/BubbleML/UI](https://github.com/isi-usc-edu/qb-gsee-benchmark/tree/main/BubbleML/UI)
- Role: ML system development for quantum algorithm evaluation

I'm actively building out additional public examples as I transition into AI safety research, focusing on:

- **Mechanistic interpretability**: Understanding what's happening inside neural networks
- **Systematic evaluation frameworks**: Rigorous testing methodologies for AI safety
- **Epistemic uncertainty**: How models represent what they know vs. don't know
- **Gaussian processes and probabilistic ML**: Uncertainty quantification for safety-critical systems

### Recent Projects

- **[Gaussian Process Regression](./gaussian-process-regression)**: Tutorial on uncertainty quantification using atmospheric COâ‚‚ data
- **[Face Detection](./face-detection)**: Real-time face detection using OpenCV (personal project for an interactive toy for my daughter)

## Background

- **PhD in Computer Science** (University of Minnesota) - dissertation on human psychophysics and visual perception
- **17+ years of ML/AI development** in manufacturing, aerospace, and government applications
- **Expertise**: Computer vision, GANs, deep learning research, systematic testing, experimental design
- **Publications**: Peer-reviewed research in computer vision, machine learning, and human perception ([Google Scholar](https://scholar.google.com/citations?user=hIH9Gc4AAAAJ))

## Current Interests

I'm exploring career opportunities in AI safety and effective altruism, with particular interest in:
- Evaluation and red-teaming for dangerous capabilities
- Understanding how fine-tuning can corrupt safety training
- Developing robust methods to detect when AI systems are operating outside their knowledge boundaries

## Contact

I'm happy to discuss my technical work and provide code samples during interviews. For professional inquiries, please reach out through my application materials or LinkedIn.

**Research Profile**: [Google Scholar](https://scholar.google.com/citations?user=hIH9Gc4AAAAJ)

---

*Note: The repositories and contributions here represent publicly shareable work from government-funded research and learning projects as I transition into AI safety research. They don't reflect the full scope of my professional work, the majority of which remains proprietary.*
