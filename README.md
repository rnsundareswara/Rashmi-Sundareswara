# Rashmi-Sundareswara


**Research Scientist | Machine Learning & AI Safety**

I'm a Research Scientist with 17+ years of experience designing, developing, and prototyping ML systems for government (DARPA / IARPA) applications, vehicle (GM) and aerospace (Boeing) manufacturing and fault prediction and quantum applications.

## About My GitHub

You'll notice this profile doesn't contain extensive code repositories from my professional work. This is by design, not by accident. My previous research at HRL Laboratories and on government-funded projects involved proprietary systems with strict intellectual property policies that prohibited public code sharing.

### Public Contributions

While most of my work remains proprietary, I have contributed to public repositories where permitted:

**DARPA Quantum Benchmarking (QB-GSEE)**: Designed and developed visualization for a structured framework, including the UI for evaluating the performance of both classical and quantum solvers on diverse GSEE problem instances using Machine Learning.  learning components for quantum benchmarking as part of DARPA's Quantum Benchmarking initiative.
- Repository: [qb-gsee-benchmark/BubbleML/UI](https://github.com/isi-usc-edu/qb-gsee-benchmark/tree/main/BubbleML/UI)

I'm actively building out additional public examples as I transition into AI safety research, focusing on:

- **Mechanistic interpretability**: Understanding what's happening inside neural networks
- **Epistemic uncertainty**: How models represent what they know vs. don't know
- **Gaussian processes and probabilistic ML**: Uncertainty quantification for safety-critical systems

### Personal Projects

- **[Gaussian Process Regression](./gaussian-process-regression)**: Experimenting with uncertainty quantification using GPR
- Currently implementing a hierarchical GPR.
- **[Face Detection](./face-detection)**: Real-time face detection using OpenCV (personal project for an interactive toy for my daughter)

## Background

- **PhD in Computer Science** (University of Minnesota) - dissertation on computational perception exploring human visual bistability and bayes-optimal 3D construction.
- **17+ years of ML/AI development** in manufacturing, aerospace, and government applications
- **Expertise**: Computer vision, GANs, deep learning research, systematic testing, experimental design
- **Publications**: Peer-reviewed research in computer vision, machine learning, and human perception ([Google Scholar](https://scholar.google.com/citations?user=hIH9Gc4AAAAJ))

## Current Interests

I'm exploring career opportunities in AI safety, with particular interest in:
- Evaluation and red-teaming for dangerous capabilities
- Understanding how fine-tuning can corrupt safety training
- Developing robust methods to detect when AI systems are operating outside their knowledge boundaries

## Contact

I'm happy to discuss my technical work. For professional inquiries, please reach out through email (kollibyle@gmail.com) or LinkedIn.

**Research Profile**: [Google Scholar](https://scholar.google.com/citations?user=hIH9Gc4AAAAJ)

---

*Note: The repositories and contributions here represent publicly shareable work from government-funded research and learning projects as I transition into AI safety research. They don't reflect the full scope of my professional work, the majority of which remains proprietary.*
